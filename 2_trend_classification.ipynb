{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2c0727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from dataset_model import CryptoDataset\n",
    "from models.LSTM_base import BaseLSTM\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb67db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 定义组合 transform\n",
    "def future_return_to_bs_class(sample):\n",
    "    sample['y'] = (sample['y'] >= 0.000081).float()\n",
    "    return sample\n",
    "\n",
    "def make_minmax_transform(min_f: torch.Tensor, max_f: torch.Tensor):\n",
    "    denom = (max_f - min_f).clamp_min(1e-8)\n",
    "    def _t(sample):\n",
    "        sample['x'] = (sample['x'] - min_f) / denom\n",
    "        return sample\n",
    "    return _t\n",
    "\n",
    "def compose(*funcs):\n",
    "    def _t(sample):\n",
    "        for f in funcs:\n",
    "            sample = f(sample)\n",
    "        return sample\n",
    "    return _t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "21ffaa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 先用“无 transform”的数据集计算训练集的全局 min/max（按特征列）\n",
    "feature_cols = ['open', 'high', 'low', 'close', 'volume', 'ema_20', 'ema_60',\n",
    "       'ema_100', 'ema_200', 'macd_20_60', 'macd_10_20', 'adx_10', 'adx_20',\n",
    "       'adx_60', 'rsi_7', 'rsi_20', 'rsi_60', 'stoch_k_10', 'stoch_k_30',\n",
    "       'stoch_k_100', 'roc_rsi_10', 'roc_rsi_20', 'roc_rsi_50', 'atr_20',\n",
    "       'atr_60', 'atr_100', 'bb_width', 'bb_percent', 'obv', 'vwap', 'mom_5',\n",
    "       'mom_20', 'mom_50', 'proc_5', 'proc_20', 'vol_ma_20', 'vol_ma_60']\n",
    "past_period = 30\n",
    "future_period = 5\n",
    "base = CryptoDataset(\n",
    "    root_path='data/BTC/raw/',\n",
    "    feature_cols=feature_cols,\n",
    "    target_col='close',\n",
    "    past_period=past_period,\n",
    "    future_period=future_period,\n",
    "    transform=None,  # 先不要 transform\n",
    ")\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(base) * train_ratio)\n",
    "\n",
    "# 假设 base.x 形状是 [T, F]，从训练时间段估计 min/max\n",
    "min_feature = base.x[:train_size + past_period].min(axis=0).values\n",
    "max_feature = base.x[:train_size + past_period].max(axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11006f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 构建带 transform 的数据集（先归一化，再做二分类标签）\n",
    "norm_t = make_minmax_transform(min_feature, max_feature)\n",
    "full_ds = CryptoDataset(\n",
    "    root_path='data/BTC/raw/',\n",
    "    feature_cols=feature_cols,\n",
    "    target_col='close',\n",
    "    past_period=past_period,\n",
    "    future_period=future_period,\n",
    "    transform=compose(norm_t, future_return_to_bs_class),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3d5670d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<dataset_model.CryptoDataset at 0x17915de66d0>,\n",
       " {'x': tensor([[0.0266, 0.0263, 0.0278,  ..., 0.5012, 0.0613, 0.1429],\n",
       "          [0.0266, 0.0262, 0.0279,  ..., 0.5072, 0.0600, 0.1426],\n",
       "          [0.0268, 0.0265, 0.0281,  ..., 0.5062, 0.0578, 0.1424],\n",
       "          ...,\n",
       "          [0.0271, 0.0265, 0.0282,  ..., 0.5133, 0.0275, 0.0742],\n",
       "          [0.0270, 0.0265, 0.0281,  ..., 0.5093, 0.0288, 0.0731],\n",
       "          [0.0268, 0.0262, 0.0280,  ..., 0.5127, 0.0272, 0.0712]]),\n",
       "  'y': tensor([0.])})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds, full_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "790e5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 划分子集并构建 DataLoader（注意 DataLoader 不接收 transform）\n",
    "train_ds = Subset(full_ds, list(range(train_size)))\n",
    "test_ds  = Subset(full_ds, list(range(train_size, len(full_ds))))\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=len(test_ds), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "51f96f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "in_channels = full_ds.feature_dim\n",
    "out_channels = 1\n",
    "hidden_channels = 32\n",
    "num_layers = 2\n",
    "dropout = 0.6\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-5\n",
    "num_epochs = 30\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2327e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = BaseLSTM(in_channels, hidden_channels, num_layers, out_channels, dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "75549a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(out, gt):\n",
    "    return (F.sigmoid(out).round() == gt).sum().item() / len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b23803e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iteration(model, optimizer, pbar, criterion, train_dataloader, epoch, writer, measure_acc=False,\n",
    "                    device=None):\n",
    "    \"\"\"\n",
    "    Train iteration\n",
    "    :param model: Model to train\n",
    "    :param optimizer: Optimizer to use (Adam, ...)\n",
    "    :param pbar: tqdm progress bar\n",
    "    :param criterion: Loss function to use (MSE, CrossEntropy, ...)\n",
    "    :param train_dataloader: Train data loader\n",
    "    :param epoch: Current epoch\n",
    "    :param writer: Tensorboard writer\n",
    "    :param measure_acc: Whether to measure accuracy or not (for classification tasks)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    outs = torch.tensor([])\n",
    "    gts = torch.tensor([])\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data['x'].to(device))\n",
    "        loss = criterion(out, data['y'].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix({\"Batch\": f\"{(idx + 1) / len(train_dataloader) * 100:.1f}%\"})\n",
    "        writer.add_scalar(\"Loss/Train Loss\", loss.item(), epoch * len(train_dataloader) + idx)\n",
    "\n",
    "        outs = torch.cat((outs, out.detach().cpu()), dim=0)\n",
    "        gts = torch.cat((gts, data['y'].detach().cpu()), dim=0)\n",
    "\n",
    "   \n",
    "    acc = measure_accuracy(outs, gts)\n",
    "    writer.add_scalar(\"Accuracy/Train Accuracy\", acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "706a2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_iteration(model, criterion, test_dataloader, epoch, writer, measure_acc=False, device=None):\n",
    "    \"\"\"\n",
    "    Test iteration\n",
    "    :param model: Model to test\n",
    "    :param criterion: Loss function to use (MSE, CrossEntropy, ...)\n",
    "    :param test_dataloader: Test data loader\n",
    "    :param epoch: Current epoch\n",
    "    :param writer: Tensorboard writer\n",
    "    :param measure_acc: Whether to measure accuracy or not (for classification tasks)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    outs = torch.tensor([])\n",
    "    gts = torch.tensor([])\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        out = model(data['x'].to(device))\n",
    "        loss = criterion(out, data['y'].to(device))\n",
    "        writer.add_scalar(\"Loss/Test Loss\", loss.item(), epoch * len(test_dataloader) + idx)\n",
    "\n",
    "        outs = torch.cat((outs, out.detach().cpu()), dim=0)\n",
    "        gts = torch.cat((gts, data['y'].detach().cpu()), dim=0)\n",
    "\n",
    "    acc = measure_accuracy(outs, gts)\n",
    "    writer.add_scalar(\"Accuracy/Test Accuracy\", acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7fbedfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader, test_dataloader, num_epochs, task_title=\"\", measure_acc=False):\n",
    "    \"\"\"\n",
    "    Train function for a regression / classification model\n",
    "    :param model: Model to train\n",
    "    :param optimizer: Optimizer to use (Adam, ...)\n",
    "    :param criterion: Loss function to use (MSE, CrossEntropy, ...)\n",
    "    :param train_dataloader: Train data loader\n",
    "    :param test_dataloader: Test data loader\n",
    "    :param num_epochs: Number of epochs to train on the train dataset\n",
    "    :param task_title: Title of the tensorboard run\n",
    "    :param measure_acc: Whether to measure accuracy or not (for classification tasks)\n",
    "    \"\"\"\n",
    "    writer = SummaryWriter(f'runs/{task_title}_{datetime.now().strftime(\"%d_%m_%Hh%M\")}_{model.__class__.__name__}')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    for epoch in (pbar := trange(num_epochs, desc=\"Epochs\")):\n",
    "        train_iteration(model, optimizer, pbar, criterion, train_dataloader, epoch, writer, measure_acc, device)\n",
    "        test_iteration(model, criterion, test_dataloader, epoch, writer, measure_acc, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d436b4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 15/30 [01:49<01:49,  7.30s/it, Batch=24.7%] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_title\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBTC_Binary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasure_acc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[94], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, train_dataloader, test_dataloader, num_epochs, task_title, measure_acc)\u001b[0m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (pbar \u001b[38;5;241m:=\u001b[39m trange(num_epochs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mtrain_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasure_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     test_iteration(model, criterion, test_dataloader, epoch, writer, measure_acc, device)\n",
      "Cell \u001b[1;32mIn[92], line 24\u001b[0m, in \u001b[0;36mtrain_iteration\u001b[1;34m(model, optimizer, pbar, criterion, train_dataloader, epoch, writer, measure_acc, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     23\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m---> 24\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/Train Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader) \u001b[38;5;241m+\u001b[39m idx)\n\u001b[0;32m     26\u001b[0m outs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((outs, out\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     27\u001b[0m gts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((gts, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_loader, test_loader, num_epochs, task_title=\"BTC_Binary\", measure_acc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b432e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
